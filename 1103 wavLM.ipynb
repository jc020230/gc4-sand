{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRJK+ZRHDcYCFEAN11QQg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jc020230/gc4-sand/blob/main/1103%20wavLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Jx6V9IILGJ2"
      },
      "outputs": [],
      "source": [
        "!pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "bG5BLSDSLXCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/drive/MyDrive/SAND_Challenge_task1_dataset/task1/sand_task_1.xlsx'\n",
        "\n",
        "\n",
        "try:\n",
        "    df_all = pd.read_excel(file_path, sheet_name='SAND - TRAINING set - Task 1')\n",
        "\n",
        "    df_trn = pd.read_excel(file_path, sheet_name='Training Baseline - Task 1')\n",
        "\n",
        "    df_val = pd.read_excel(file_path, sheet_name='Validation Baseline - Task 1')\n",
        "\n",
        "    print(\"파일 읽기 성공!\")\n",
        "    print(df_all.head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"오류: 파일을 찾을 수 없습니다.\")\n",
        "    print(f\"경로를 다시 확인해주세요: {file_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"파일을 읽는 중 오류가 발생했습니다: {e}\")"
      ],
      "metadata": {
        "id": "00OV3eKJLb0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_ids = df_trn['ID'].tolist()\n",
        "val_ids = df_val['ID'].tolist()\n",
        "len(trn_ids), len(val_ids)"
      ],
      "metadata": {
        "id": "bV3gVEB8LhI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trn_folder = '/content/drive/MyDrive/SAND_Challenge_task1_dataset/task1/training'\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "from pathlib import Path\n",
        "\n",
        "# training 폴더의 모든 wav 파일 찾기\n",
        "wav_files = []\n",
        "wav_info_dict = {}\n",
        "wav_files_trn = []\n",
        "wav_files_val = []\n",
        "\n",
        "# rhythmPA와 rhythmTA 폴더에서 wav 파일 찾기\n",
        "for subfolder in ['phonationA', 'phonationE','phonationI', 'phonationO', 'phonationU','rhythmKA','rhythmPA', 'rhythmTA']:\n",
        "    folder_path = os.path.join(trn_folder, subfolder)\n",
        "    if os.path.exists(folder_path):\n",
        "        # glob을 사용하여 wav 파일 찾기\n",
        "        pattern = os.path.join(folder_path, '*.wav')\n",
        "        files = glob.glob(pattern)\n",
        "        wav_files.extend(files)\n",
        "\n",
        "print(f\"총 {len(wav_files)}개의 wav 파일을 찾았습니다.\")\n",
        "\n",
        "# 파일 경로에서 ID 추출하고 라벨 정보 매칭\n",
        "for file_path in wav_files:\n",
        "    # 파일명에서 ID 추출 (IDxxx 형태)\n",
        "    filename = os.path.basename(file_path)\n",
        "    id_match = re.search(r'(ID\\d+)', filename)\n",
        "\n",
        "    if id_match:\n",
        "        id_num = id_match.group(1)  # ID 번호를 정수로 변환\n",
        "\n",
        "        # 트레인/밸리데이션 데이터셋에 따라 파일 경로 분류\n",
        "        if id_num in trn_ids:\n",
        "            wav_files_trn.append(file_path)\n",
        "        elif id_num in val_ids:\n",
        "            wav_files_val.append(file_path)\n",
        "\n",
        "        # df_all에서 해당 ID의 정보 찾기\n",
        "        matching_row = df_all[df_all['ID'] == id_num]\n",
        "\n",
        "        ## task_type 정보 추가\n",
        "        if not matching_row.empty:\n",
        "            # 라벨 정보 추출\n",
        "            label_info = {\n",
        "                'file_path': file_path,\n",
        "                'id': id_num,\n",
        "                'class': matching_row['Class'].values[0],\n",
        "                'age': matching_row['Age'].values[0],\n",
        "                'sex': matching_row['Sex'].values[0]\n",
        "            }\n",
        "            wav_info_dict[file_path] = label_info\n",
        "        else:\n",
        "            print(f\"Warning: ID {id_num}에 대한 라벨 정보를 찾을 수 없습니다. 파일: {filename}\")\n",
        "    else:\n",
        "        print(f\"Warning: 파일명에서 ID를 추출할 수 없습니다: {filename}\")\n",
        "\n",
        "print(f\"\\n라벨 정보가 매칭된 파일: {len(wav_info_dict)}개\")\n",
        "\n"
      ],
      "metadata": {
        "id": "O_LqRJyqLqdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(wav_files), len(wav_files_trn), len(wav_files_val)"
      ],
      "metadata": {
        "id": "W4_4kGozLsO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wav_info_dict[wav_files[0]]"
      ],
      "metadata": {
        "id": "xWmUfKFCLxvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers scikit-learn"
      ],
      "metadata": {
        "id": "UE95edp4L131"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import WavLMModel, AutoFeatureExtractor\n",
        "import librosa\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import warnings"
      ],
      "metadata": {
        "id": "_D7M8FEFL21X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# WavLM 모델과 피처 추출기 로드 (16kHz로 학습됨)\n",
        "MODEL_NAME = \"microsoft/wavlm-base-plus\"\n",
        "TARGET_SR = 16000 # WavLM은 16kHz로 사전 학습되었습니다.\n",
        "\n",
        "print(f\"{MODEL_NAME} 모델 로드 중...\")\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(MODEL_NAME)\n",
        "model = WavLMModel.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "# 모델을 \"동결\" (학습되지 않도록 평가 모드로 설정)\n",
        "model.eval()\n",
        "print(\"모델 로드 완료 및 동결.\")"
      ],
      "metadata": {
        "id": "hWI_BGCoL9iX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_list, label_dict, target_sr):\n",
        "    features = []\n",
        "    labels = []\n",
        "\n",
        "    # file_list (wav_files_trn 또는 wav_files_val)를 순회합니다.\n",
        "    for file_path in tqdm(file_list, desc=\"특징 추출 중\"):\n",
        "        try:\n",
        "            # 1. 오디오 로드 및 16kHz로 리샘플링\n",
        "            waveform, sr = librosa.load(file_path, sr=target_sr, mono=True)\n",
        "\n",
        "            # 2. 피처 추출기로 전처리\n",
        "            inputs = feature_extractor(waveform, sampling_rate=target_sr, return_tensors=\"pt\", padding=True)\n",
        "            inputs = inputs.to(device)\n",
        "\n",
        "            # 3. 모델 통과 (그래디언트 계산 안 함)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "            # 4. 특징 벡터 집계 (평균 풀링)\n",
        "            # outputs.last_hidden_state shape: (1, seq_len, 768)\n",
        "            # 시간 축(dim=1)에 대해 평균을 내어 (1, 768) 형태로 만듦\n",
        "            embedding = torch.mean(outputs.last_hidden_state, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "            features.append(embedding)\n",
        "\n",
        "            # 5. 레이블 가져오기 (기존 wav_info_dict 활용)\n",
        "            label = label_dict[file_path]['class'] - 1  # 0부터 시작하도록 조정\n",
        "            labels.append(label)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"파일 처리 오류 {file_path}: {e}\")\n",
        "\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# --- 특징 추출 실행 ---\n",
        "# (노트북 7번 셀까지 실행해서 wav_files_trn, wav_files_val, wav_info_dict가 메모리에 있어야 합니다)\n",
        "\n",
        "print(\"Train 데이터 특징 추출 시작...\")\n",
        "X_train, y_train = extract_features(wav_files_trn, wav_info_dict, target_sr=TARGET_SR)\n",
        "\n",
        "print(\"Validation 데이터 특징 추출 시작...\")\n",
        "X_val, y_val = extract_features(wav_files_val, wav_info_dict, target_sr=TARGET_SR)\n",
        "\n",
        "print(f\"\\nTrain 특징 형태: {X_train.shape}, Train 레이블 형태: {y_train.shape}\")\n",
        "print(f\"Val 특징 형태: {X_val.shape}, Val 레이블 형태: {y_val.shape}\")"
      ],
      "metadata": {
        "id": "6rsii_LFMAV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM과 같은 모델을 위해 특징 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "print(\"특징 스케일링 완료.\")"
      ],
      "metadata": {
        "id": "I2rNH3VlMDXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. SVM (Support Vector Machine) 분류기 ---\n",
        "print(\"\\n--- SVM 분류기 학습 및 평가 ---\")\n",
        "# class_weight='balanced'는 기존 코드의 WeightedRandomSampler와 유사한 역할(불균형 처리)을 합니다.\n",
        "svm_classifier = SVC(kernel='rbf', C=1.0, class_weight='balanced', random_state=42)\n",
        "\n",
        "# 스케일링된 데이터로 학습\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 검증 데이터로 평가\n",
        "y_pred_svm = svm_classifier.predict(X_val_scaled)\n",
        "f1_svm = f1_score(y_val, y_pred_svm, average='macro') # average='macro'가 average f1 score입니다.\n",
        "\n",
        "print(f\"SVM Macro F1 Score: {f1_svm:.4f}\")\n",
        "print(classification_report(y_val, y_pred_svm))\n",
        "\n",
        "\n",
        "# --- 2. RandomForest 분류기 ---\n",
        "print(\"\\n--- RandomForest 분류기 학습 및 평가 ---\")\n",
        "rf_classifier = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42, n_jobs=-1)\n",
        "\n",
        "# RandomForest는 스케일링이 필수는 아닙니다 (원본 X_train 사용)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# 검증 데이터로 평가\n",
        "y_pred_rf = rf_classifier.predict(X_val)\n",
        "f1_rf = f1_score(y_val, y_pred_rf, average='macro')\n",
        "\n",
        "print(f\"RandomForest Macro F1 Score: {f1_rf:.4f}\")\n",
        "print(classification_report(y_val, y_pred_rf))"
      ],
      "metadata": {
        "id": "F_VKJBXoMKXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation"
      ],
      "metadata": {
        "id": "WY1WmnvaMUMq"
      }
    }
  ]
}